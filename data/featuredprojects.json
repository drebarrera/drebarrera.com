[
  {
    "id": 0,
    "index": 0,
    "identifier": "arachnode",
    "title": "ArachNode",
    "description": "Developing and training an AI model to find information on the web.",
    "link": "View Case Study",
    "background": "#166481",
    "captureMB": "5%",
    "role": "Independent Project",
    "location": "Austin, Texas",
    "tools": ["Python", "JavaScript", "HTML", "CSS", "Chrome Extensions", "TensorFlow", "Selenium", "AWS", "AWS IAM", "AWS S3", "AWS API Gateway", "AWS Lambda"],
    "website": "https://github.com/drebarrera/ArachNode",
    "challenge": "The challenge of ArachNode was to create an AI program capable of navigating the complex and dynamic landscape of the web to identify specific information. Traditional scraping methods often fall short in handling intricate navigation and decision-making. The goal was to design an intelligent system that could provide efficient browsing behavior, making decisions on when to click on links or backtrack, and do so with over 80% accuracy, an Area Under the Curve (AUC) over 0.85, and an F1-score over 0.8.",
    "solution": "The solution, ArachNode, employs a hybrid approach, integrating feature engineering, machine learning, and advanced NLP techniques like BERT to predict efficient user actions in a web browser. A browser scraper initially collects and quantifies over 1600 DOM-based features, which a trained machine learning model uses to classify web elements into clickable, informative, or structural categories. BERT calculates the 'value of best fit' between each element's text and the user's query, selecting the most relevant action accordingly. The algorithm incorporates a backtracking mechanism, reverting to a previous page if the new document's collective NLP values are suboptimal, thereby ensuring the highest relevance to the user's query.involved designing an AI program using reinforcement learning, a method that allows the system to learn optimal navigation strategies through trial and error.",
    "choices": "The ArachNode neural network model, built using TensorFlow's Keras API, is a feed-forward, fully connected architecture with an input layer of 128 neurons, a hidden layer of 64 neurons, and an optimized output layer of 3 neurons to match the three categories: clickable, informative, and structural. The model uses ReLU activation functions for computational efficiency and softmax for the output layer. It's configured with an input shape of 1600 to accommodate the extensive feature set derived from DOM attributes. The Adam optimizer and categorical_crossentropy loss function are employed for their suitability in handling large datasets and multi-class classification. To mitigate overfitting, dropout layers have been added. Evaluation metrics include accuracy, AUC, and F1-score to provide a comprehensive assessment of the model's performance. Programmatically, data is collected using a set of Chrome Extension JavaScript functions, stored in AWS S3, and interfaced with using AWS API Gateway. Selenium Python is used for data verification collection.",
    "result": "The ArachNode project is not yet complete, but is underway with training to discriminate between clickable and non-clickable elements (two of the three classifiers given above). Using just 5 search instances with over 1200 DOM elements, the AI has proven to be 32.8% accurate with an AUC of 0.68 and F1-score of 0.45. An AUC higher than 0.5 implies that the model does not apply random guesswork, but the combination of the three metrics leave much room for improvement in precision, recall, and accuracy. The below images show data collection with a custom built Chrome Extension and API, the Python training architecture for the model, and the AI architecture for predicting user browser actions."
  },
  {
    "id": 0,
    "index": 0,
    "identifier": "shotglass",
    "title": "Shotglass Jobs",
    "description": "Changing the employment industry with an job board that will apply for you.",
    "link": "View Case Study",
    "background": "#F59300",
    "captureMB": "0px",
    "role": "President | Software Engineer",
    "location": "Austin, Texas",
    "tools": ["HTML", "CSS", "JavaScript", "jQuery", "Chrome Extensions", "Selenium", "Photoshop", "WebGen", "AWS", "AWS IAM", "AWS Route53", "AWS CloudFront", "AWS S3", "AWS API Gateway", "AWS Cognito", "AWS DynamoDB", "AWS Lambda"],
    "website": "",
    "challenge": "The challenge of Shotglass Jobs was to create a web application that could automate the tedious process of job searching by finding, assessing, and submitting applications for job postings tailored to a user's profile. The complexity lay in scraping diverse job platforms, evaluating the relevance of postings, and integrating a seamless user experience that would allow for personalized job application submissions.",
    "solution": "The solution, Shotglass Jobs, involved designing a web application that utilized data scraping techniques to gather job postings from various platforms. This is to be implemented using the ArachNode AI developed in my simultaneous project. The application assesses the relevance of these postings based on user profiles and preferences and provides an automated submission process using a Selenium Python routine. The entire application is hosted on AWS, leveraging services like S3, Route53, Cloudfront, Cognito User Database, DynamoDB, API Gateway, and AWS Lambda to ensure scalability, security, and performance.",
    "choices": "The frontend of Shotglass Jobs is designed using HTML, CSS, JavaScript, jQuery, and my Python compiler, WebGen. The backend was complex to set up, but saved me on cost and performance - using AWS services to provide hosting, authentication, and data storage for the program. The goal is to be able to provide an interface for creating and editing resume and cover letter templates. User data is already stored and retrieved by the frontend from AWS DynamoDB and AWS Cognito. API Gateway and AWS Lambda manage the serverless functions of the program.",
    "result": "Although not yet complete, the Shotglass Jobs shows great promise for providing a personalized and automated experience. The project is currently awaiting the production of the ArachNode AI (explained in another one of my projects) to provide the information search algorithm to be used by the web application. So far, the use of AWS services has ensured a scalable, secure, and efficient infrastructure, as shown in the live examples of the site below, where I have collected and displayed data with persistant authentication."
  },
  {
    "id": 0,
    "index": 0,
    "identifier": "webgen",
    "title": "WebGen Python UI Framework",
    "description": "Developing an object-oriented Python framework for frontend.",
    "link": "View Case Study",
    "background": "#614D5B",
    "captureMB": "0px",
    "role": "President | Software Engineer",
    "location": "Austin, Texas",
    "tools": ["HTML", "CSS", "JavaScript", "Python", "PHP", "jQuery"],
    "website": "https://www.drebarrera.com/webgen/",
    "challenge": "The challenge was to design a frontend web application framework that would offer an OOP alternative to existing modern frameworks. The goal was to leverage the power and flexibility of Python to create a framework that would provide developers with a more intuitive and structured way to build web applications. The project required a deep understanding of both frontend development and Python's OOP capabilities, as well as the ability to innovate beyond existing paradigms.",
    "solution": "The solution, WebGen, involved creating a new frontend web application framework that utilized Python's OOP principles. By designing a framework that allowed developers to build web applications using Python classes and objects, the project aimed to offer a more organized and intuitive development experience. The framework was designed to be flexible, efficient, and compatible with existing web technologies, providing a unique and powerful tool for web development.",
    "choices": "WebGen leverages Python's object-oriented capabilities to create a more intuitive web programming experience. With the ability to create global files and link them to specific pages, repeat frontend code structures using loops and functions, and implement JavaScript, PHP, and CSS code, the framework provides an alternative to common frameworks such as ReactJS, AngularJS, and VueJS. All Python code created is compiled into HTML code with fixed styles and dynamic classes.",
    "result": "The resulting frontend web application framework successfully provided an OOP alternative to modern frameworks, offering developers a new and intuitive way to build web applications using Python. By integrating Python's OOP principles with existing web technologies, the framework enabled more structured and organized development. Since creating WebGen, I have used it in a number of projects. WebGen's IP was acquired by an industry 4.0 software company in 2022. The images below show the simplicity of WebGen code to create flexible websites."
  }
]
