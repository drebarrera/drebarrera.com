[
  {
    "id": 0,
    "index": 0,
    "identifier": "pixelvisa",
    "title": "Pixel Visa",
    "description": "Developing a website to serve backpackers as a digital guide to global adventures.",
    "link": "View Case Study",
    "background": "linear-gradient(rgba(0,0,0,0.8), rgba(0,0,0,0.8)),url('/images/featured/pixelvisa/bg.webp') rgba(0,0,0,0.9)",
    "captureMB": "0px",
    "role": "Independent",
    "location": "Austin, Texas",
    "tools": ["Wordpress", "PHP", "JavaScript", "HTML", "CSS", "Leaflet.js", "SVG", "SVGViewer", "iconmonstr", "Local by Flywheel"],
    "website": "https://www.pixelvisa.net",
    "challenge": "In September of 2023, I decided to embark on a journey across the world - a journey which has taken me across Asia and is soon to land me in Europe. To keep a log of my travels and all of my favorite places, I created Pixel Visa - a digital guide for backpackers on journies similar to mine. In developing Pixel Visa, I worked hard to craft an interface that seamlessly weaved the narrative of a backpacker's journey. This task involved not only curating and integrating online information but also in creating an intuitive and aesthetically pleasing website to convey this narrative with real on-site experiences. The goal was to strike a balance between functionality and an engaging design, providing users with an informative and visually enjoyable experience as they digitally explore the world and follow my story as I traverse the globe.",
    "solution": "Effectively creating a website like Pixel Visa meant finding a effective way to combine simple facts and information with personal experiences. As a result, I divided up my journey into fact sheets about individual countries, cities, experiences, and restaurants, connecting them with a custom map feature tracking my journey. This solution ensures that users get a mix of reliable information and firsthand experiences, allowing them to virtually join the backpacking adventure.",
    "choices": "Pixel Visa's design and development were carefully crafted to offer an engaging user experience. The utilization of personally collected global images adds authenticity, allowing users to visually connect with real backpacking experiences. WordPress, with its relational SQL database, efficiently organizes information, creating seamless references between countries, cities, and activities. The decision to integrate LeafletJS for custom map creation enhances the storytelling element, providing a dynamic, real-time backpacker timeline. This interactive map feature allows users to follow the journey, keeping up with the backpacker's whereabouts, activities, and experiences as they unfold. The focus on flexible mobile interfacing ensures a user-friendly experience, optimizing the interface for accessibility across various devices. Overall, these design and development choices converge to create Pixel Visa as a visually compelling, informative, and accessible platform for backpacking enthusiasts worldwide.",
    "result": "Pixel Visa delivers a dynamic and informative platform with a homepage showcasing captivating journey highlights, offering users a quick glimpse into the diverse backpacking experiences. The map page provides a visual journey timeline, allowing users to track the backpacker's route in real-time. Additionally, individual factual pages for each city, country, activity, restaurant, coworking space, and hostel/hotel offer in-depth information. These dedicated pages empower backpackers to make well-informed decisions, providing insights into various aspects of each destination. By combining engaging highlights on the homepage, a real-time journey map, and comprehensive individual pages, Pixel Visa creates a user-friendly and comprehensive resource for backpackers, facilitating informed decision-making throughout their global adventures."
  },
  {
    "id": 0,
    "index": 0,
    "identifier": "arachnode",
    "title": "ArachNode",
    "description": "Developing and training an AI model to find information on the web with high metric performance.",
    "link": "View Case Study",
    "background": "#166481",
    "captureMB": "5%",
    "role": "Independent",
    "location": "Austin, Texas",
    "tools": ["Python", "JavaScript", "HTML", "CSS", "Chrome Extensions", "TensorFlow", "Selenium", "AWS", "AWS IAM", "AWS S3", "AWS API Gateway", "AWS Lambda", "Git"],
    "website": "https://github.com/drebarrera/ArachNode",
    "challenge": "The challenge of ArachNode was to create an AI program capable of navigating the complex and dynamic landscape of the web to identify specific information. Traditional scraping methods often fall short in handling intricate navigation and decision-making. The goal was to design an intelligent system that could provide efficient browsing behavior, making decisions on when to click on links or backtrack, and do so with over 80% accuracy, an Area Under the Curve (AUC) over 0.85, and an F1-score over 0.8.",
    "solution": "The solution, ArachNode, employs a hybrid approach, integrating feature engineering, machine learning, and advanced NLP techniques like BERT to predict efficient user actions in a web browser. A browser scraper initially collects and quantifies over 1600 DOM-based features, which a trained machine learning model uses to classify web elements into clickable, informative, or structural categories. BERT calculates the 'value of best fit' between each element's text and the user's query, selecting the most relevant action accordingly. The algorithm incorporates a backtracking mechanism, reverting to a previous page if the new document's collective NLP values are suboptimal, thereby ensuring the highest relevance to the user's query.involved designing an AI program using reinforcement learning, a method that allows the system to learn optimal navigation strategies through trial and error.",
    "choices": "The ArachNode neural network model, built using TensorFlow's Keras API, is a feed-forward, fully connected architecture with an input layer of 1600 neurons, two hidden layers of 800 and 400 neurons respectively, and an optimized output layer of 3 neurons to match the three categories: clickable, informative, and structural. The model uses ReLU activation functions for computational efficiency and softmax for the output layer. It's configured with an input shape of 1600 to accommodate the extensive feature set derived from DOM attributes. The Adam optimizer and categorical_crossentropy loss function are employed for their suitability in handling large datasets and multi-class classification. To mitigate overfitting, dropout layers have been added. Evaluation metrics include accuracy, AUC, and F1-score to provide a comprehensive assessment of the model's performance. Programmatically, data is collected using a set of Chrome Extension JavaScript functions, stored in AWS S3, and interfaced with using AWS API Gateway. Selenium Python is used for data verification collection.",
    "result": "The ArachNode project is not yet complete, but is underway with training to discriminate between clickable and non-clickable elements (two of the three classifiers given above). Using just 5 search instances with over 1200 DOM elements, the AI has proven to be 32.8% accurate with an AUC of 0.68 and F1-score of 0.45. An AUC higher than 0.5 implies that the model does not apply random guesswork, but the combination of the three metrics leave much room for improvement in precision, recall, and accuracy. The below images show data collection with a custom built Chrome Extension and API, the Python training architecture for the model, and the AI architecture for predicting user browser actions."
  },
  {
    "id": 0,
    "index": 0,
    "identifier": "shotglass",
    "title": "Shotglass Jobs",
    "description": "Changing the employment industry with a job board that will apply for you.",
    "link": "View Case Study",
    "background": "#F59300",
    "captureMB": "0px",
    "role": "Independent",
    "location": "Austin, Texas",
    "tools": ["HTML", "CSS", "JavaScript", "jQuery", "Chrome Extensions", "Selenium", "Photoshop", "WebGen", "AWS", "AWS IAM", "AWS Route53", "AWS CloudFront", "AWS S3", "AWS API Gateway", "AWS Cognito", "AWS DynamoDB", "AWS Lambda", "Git"],
    "website": "",
    "challenge": "The challenge of Shotglass Jobs was to create a web application that could automate the tedious process of job searching by finding, assessing, and submitting applications for job postings tailored to a user's profile. The complexity lay in scraping diverse job platforms, evaluating the relevance of postings, and integrating a seamless user experience that would allow for personalized job application submissions.",
    "solution": "The solution, Shotglass Jobs, involved designing a web application that utilized data scraping techniques to gather job postings from various platforms. This is to be implemented using the ArachNode AI developed in my simultaneous project. The application assesses the relevance of these postings based on user profiles and preferences and provides an automated submission process using a Selenium Python routine. The entire application is hosted on AWS, leveraging services like S3, Route53, Cloudfront, Cognito User Database, DynamoDB, API Gateway, and AWS Lambda to ensure scalability, security, and performance.",
    "choices": "The frontend of Shotglass Jobs is designed using HTML, CSS, JavaScript, jQuery, and my Python compiler, WebGen. The backend was complex to set up, but saved me on cost and performance - using AWS services to provide hosting, authentication, and data storage for the program. The goal is to be able to provide an interface for creating and editing resume and cover letter templates. User data is already stored and retrieved by the frontend from AWS DynamoDB and AWS Cognito. API Gateway and AWS Lambda manage the serverless functions of the program.",
    "result": "Although not yet complete, the Shotglass Jobs shows great promise for providing a personalized and automated experience. The project is currently awaiting the production of the ArachNode AI (explained in another one of my projects) to provide the information search algorithm to be used by the web application. So far, the use of AWS services has ensured a scalable, secure, and efficient infrastructure, as shown in the live examples of the site below, where I have collected and displayed data with persistant authentication."
  },
  {
    "id": 0,
    "index": 0,
    "identifier": "webgen",
    "title": "WebGen Python UI Framework",
    "description": "Developing an object-oriented Python framework for frontend.",
    "link": "View Case Study",
    "background": "#614D5B",
    "captureMB": "0px",
    "role": "Independent",
    "location": "Austin, Texas",
    "tools": ["HTML", "CSS", "JavaScript", "Python", "PHP", "jQuery", "Git"],
    "website": "https://www.drebarrera.com/webgen/",
    "challenge": "The challenge was to design a frontend web application framework that would offer an OOP alternative to existing modern frameworks. The goal was to leverage the power and flexibility of Python to create a framework that would provide developers with a more intuitive and structured way to build web applications. The project required a deep understanding of both frontend development and Python's OOP capabilities, as well as the ability to innovate beyond existing paradigms.",
    "solution": "The solution, WebGen, involved creating a new frontend web application framework that utilized Python's OOP principles. By designing a framework that allowed developers to build web applications using Python classes and objects, the project aimed to offer a more organized and intuitive development experience. The framework was designed to be flexible, efficient, and compatible with existing web technologies, providing a unique and powerful tool for web development.",
    "choices": "WebGen leverages Python's object-oriented capabilities to create a more intuitive web programming experience. With the ability to create global files and link them to specific pages, repeat frontend code structures using loops and functions, and implement JavaScript, PHP, and CSS code, the framework provides an alternative to common frameworks such as ReactJS, AngularJS, and VueJS. All Python code created is compiled into HTML code with fixed styles and dynamic classes.",
    "result": "The resulting frontend web application framework successfully provided an OOP alternative to modern frameworks, offering developers a new and intuitive way to build web applications using Python. By integrating Python's OOP principles with existing web technologies, the framework enabled more structured and organized development. Since creating WebGen, I have used it in a number of projects. WebGen's IP was acquired by an industry 4.0 software company in 2022. The images below show the simplicity of WebGen code to create flexible websites."
  }
]
